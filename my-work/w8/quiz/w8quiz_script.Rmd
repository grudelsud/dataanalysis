w8 quiz
========================================================

# q1

A: False discovery rate = 0.20 False positive rate = 0.09

# q2

```{r}
set.seed(3343)
pValues = rep(NA,100)
for(i in 1:100){
  z = rnorm(20)
  x = rnorm(20)
  y = rnorm(20,mean=0.5*x)
  pValues[i] = summary(lm(y ~ x))$coef[2,4]
}
```

How many are significant at the alpha = 0.1 level when controlling the family wise error rate using the methods described in the lectures? When controlling the false discovery rate at the alpha = 0.2 level as described in the lectures?

```{r}
# FWER
sum(p.adjust(pValues,method="bonferroni") < 0.1)

# FDR
sum(p.adjust(pValues,method="BH") < 0.1)
```

A: FWER = 7 FDR = 61

# q3

Suppose I want to generate data from the following model with a simulation:
```{r}
y = b0 + b1*x + b2*z + e
```
where b0=1, b1=2, b2=3 and x, z, and e are normally distributed. Which one of the following is not a step in the simulation process?

A: Generate a random sample of values for b_0, b_1, and b_2

# q4

Suppose data are generated from a model:

```{r}
library(MASS)

runs = 1000
length = 20
est1 <- rep(NA, runs)
est1r <- rep(NA, runs)
est2 <- rep(NA, runs)
est2r <- rep(NA, runs)

for(i in 1:runs) {
  x = rnorm(length)
  e = rnorm(length)
  b0 = 1
  b1 = 2
  y = b0 + b1*x + e

  # case 1: some higher x values are missing
  xm <- x
  xm[which(rbinom(length, 1, 0.5) & (xm > 1))] = NA
  lm1 <- lm(y ~ xm)
  est1[i] <- lm1$coeff[2]
  lm1r <- rlm(y ~ xm)
  est1r[i] <- lm1r$coeff[2]

  # case 2: some higher y values are missing
  ym <- y
  ym[which(rbinom(length, 1, 0.5) & (ym > 2))] = NA
  lm2 <- lm(ym ~ x)
  est2[i] <- lm2$coeff[2]
  lm2r <- rlm(ym ~ x)
  est2r[i] <- lm2r$coeff[2]
}

mean(est1)
mean(est2)
```

where b0=1, b1=2 and x and e both have a normal distribution with mean zero and variance one. After the data are created, some data are lost. Use the lm() function in base R for model fitting. 
Case 1: Build a simulation where all values of y are observed but higher values of x are likely to be missing. Does the estimate of b1 change on average? If so how? 
Case 2 Build a simulation where all values of x are observed but higher values of y are likely to be missing. Does the estimate of b1 change on average? If so how?

A: Case 1: b1 is estimated correctly Case 2: b1 is underestimated

# q5

Exactly as in the last question, suppose data are generated from a model: y = b0 + b1*x + e where b0=1, b1=2 and x and e both have a normal distribution with mean zero and variance one. After the data are created, some data are lost. Answer the same questions below, but this time, use the rlm() function in the MASS package to fit the linear model instead of the lm() function in base R. Case 1: Build a simulation where all values of y are observed but higher values of x are likely to be missing. Does the estimate of b1 change on average? If so how? Case 2 Build a simulation where all values of x are observed but higher values of y are likely to be missing. Does the estimate of b1 change on average? If so how?

```{r}
# run the code above, then print the following
mean(est1r)
mean(est2r)
```
A: Case 1: b1 is estimated correctly Case 2: b1 is underestimated
