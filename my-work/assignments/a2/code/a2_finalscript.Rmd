2nd Assignment
========================================================

Todo
--------------------------------------------------------
Your task is to build a function that predicts what activity a subject is performing based on the quantitative measurements from the Samsung phone. For this analysis your training set must include the data from subjects 1, 3, 5, and 6.  But you may use more subjects data to train if you wish. Your test set is the data from subjects 27, 28, 29, and 30, but you may use more data to test. Be careful that your training/test sets do not overlap. 

Introduction
--------------------------------------------------------
Research in activity and gesture recognition is quite important nowadays [ref. 3], as it can help in several different fields, such as video surveillance, health, disease prevention and much more. Since the introduction of smartphones, and most importantly the accelerometers mounted in the devices, along with their wide adoption across all countries, plenty of data describing different gestures has become availble. This data can be used proficiently to monitor and predict activities of people carrying the device, to help them expoiting the goals fixed by a specific application that takes advantage of these values. As a matter of fact, a simplified version of the predictor described in this paper has been used to teach first aid techniques in a project financed by the Technology Strategy Board and lead by the Resuscitation Council in the UK [ref. 7].
In this paper we will show how a set of data can be used to train models and predict what activity is performed by a user producing comparable values through an accelerometer mounted on a mobile device.

Data collection
--------------------------------------------------------
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING UPSTAIRS, WALKING DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. [ref. 1]

All of the columns of the data set (except the last two) represents one measurement from the Samsung phone. The variable subject indicates which subject was performing the tasks when the measurements were taken. The variable activity tells what activity they were performing. [ref. 2]

```{r}

# uncomment to download it again
# data_url <- 'https://spark-public.s3.amazonaws.com/dataanalysis/samsungData.rda'
# download.file(data_url, '../data/samsungData.rda', method='curl')

# show date for the records
# download_when <- date()
# print(download_when)

# the file available here was downloaded on Fri Mar 8th, at 11:16 AM
load('../data/samsungData.rda')

```

Exploratory analysis
--------------------------------------------------------
Great help has been provided by the community in the initial approach to understanding how the acceleramoter data is structured, through a discussion around differences between total body acceleration, gravity, jerk and all related elements [ref. 4].

```{r}
names(samsungData)[1:40]
names(samsungData)[41:80]
names(samsungData)[81:120]

table(samsungData$activity)
class(samsungData$activity)

table(samsungData$subject)
dim(table(samsungData$subject))
```

* 1st 40 columns contain data related to body acceleration along the 3 axes, this is taking into account the gravity vector
* columns 41-80 contain data related to gravity acceleration only along the 3 axes
* columns 81-120 contain data related to acceleration jerk for the body along the 3 axes (jerk is 3rd order derivative of position, equals 2nd order derivative of velocity, 1st order derivative of acceleration [ref. 5])
* further exploration shows that: columns 121-160 contain body gyroscope, 161-200 body gyroscope jerk, and up to column 265 other derivatives in the time domain, while from column 266 to column 554 the values transformed in the frequency domain, then columns 556 to 561 for the angles between accelerometer vectors and the last two columns dedicated to subject and activity labelings
* table of activities show how they are equally distributed across 6 items: laying, sitting, standing, walk, walkdown, walkup
* table of subjects show how they are equally distributed across 21 people, for the purpose of this analysis, we are going to use subjects labeled 1, 3, 5, 6 for training sets and subjects 27, 28, 29, and 30 for tests.

```{r}
summary(samsungData[1:40])
boxplot(samsungData[1:40],col="#ff0099")
```

a quick observation of the 1st 40 columns reveals that there are not empty values in the dataset, and a boxplot shows that they are all normalized in a [-1,1] interval, so it should not need removal of outliers. the same applies the all numeric values contained in the dataset.
Calling the summary function also reveals that reserved R keywords are used for variable names, so to stay on a safe side, when creating the training and test set, they will be converted using R function make.names.

The activity field has been stored as character so it will be converted to factor in the training/validation/test sets.

```{r}
# transforming a bit the samsungData so as to cleanup names
samsung_procdata <- data.frame(samsungData, check.names=TRUE)
samsung_procdata$activity <- as.factor(samsung_procdata$activity)

# preparing the training set
training_subjects <- c(1,3,5,6)
training_set <- samsung_procdata[samsung_procdata$subject %in% training_subjects,]
training_set <- training_set[order(training_set$activity),]
training_set$subject <- NULL

factor_activity <- unique(training_set$activity)

# enlarged dataset, we are using the %in% to avoid the warning: longer object length is not a multiple of shorter object length
ltraining_subjects <- c(1,3,5,6,7,8,11,19,21,22,23,25,26)
ltraining_set <- samsung_procdata[samsung_procdata$subject %in% ltraining_subjects,]
ltraining_set <- ltraining_set[order(ltraining_set$activity),]
ltraining_set$subject <- NULL

# pick a few subjects for validation set
validation_subjects <- c(14,15,16,17)
validation_set <- samsung_procdata[samsung_procdata$subject %in% validation_subjects,]
validation_set <- validation_set[order(validation_set$activity),]
validation_set$subject <- NULL

# doing the same for test set
test_subjects <- c(27,28,29,30)
test_set <- samsung_procdata[samsung_procdata$subject %in% test_subjects,]
test_set <- test_set[order(test_set$activity),]
test_set$subject <- NULL
```

We subset the whole dataframe for training, validation and tests with the subjects we want to use, then ordering by activity, cleaning up variable names and removing the column related to subjects since we don't want it to appear in the model. Dimensions of the sets are:

```{r}
dim(training_set)
dim(ltraining_set)
dim(validation_set)
dim(test_set)
```

(we also create an extended training set made of 5867 observations to validate our models without bootstrap) All the observations are consistently made of 562 variables.

Statistical modeling
--------------------------------------------------------

We are going to use the data from subjects 1,3,5,6 as training sets to create a range of regression models, using a mixture of kernel based functions (i.e. using trees, randomForests and support vector machines) taking extra care in balancing the bias / variance trade off in statistical modeling, as described in the analysis section of this paper. Particularly, given the nature of this dataset, differences in errors will be evaulated when using bootstrap techniques in favour of enlarging the dataset and creating models without sampling. A complete recap of statistical methods (regression models and bootstrap technique) mentioned in this paper can be found in [ref. 6]

Analysis
--------------------------------------------------------

After plotting values from the training set, we can see clear clusters of activities: these plots show comparable patterns no matter the variable chosen for the y-axis [fig. 1a], indicating that it is worth creating a regression model that uses all the variables in the data set, we will then proceed with further exploration in order to reduce the complexity of our models.
We load the required libraries and set a seed so as to generate a consistent set of training models, so that errors on validation and test will be always consistent.

```{r}
library(randomForest)
library(e1071)
library(tree)

set.seed(987654321)
```

We start creating 3 different models using the basic training set: tree, random forest and svm.

```{r}
mod_randomforest <- randomForest(activity ~ ., data=training_set, prox=TRUE)
mod_svm <- svm(activity ~ ., data=training_set)
mod_tree <- tree(activity ~ ., data=training_set)

print(mod_randomforest)
print(mod_svm)
print(mod_tree)
```

Random forest with 500 trees with bootstrap shows an error < 4% in activity classification, while tree splits show that first variables used are all in the time domain. Now we can do some prediction on the validation test to see how the models behave.

```{r}
predvalid_randomforest <- predict(mod_randomforest, validation_set)
predvalid_svm <- predict(mod_svm, validation_set)
predvalid_tree <- predict(mod_tree, validation_set, type="class")

errvalid_randomforest <- sum(predvalid_randomforest != validation_set$activity) / length(validation_set$activity)
print(errvalid_randomforest)

errvalid_svm <- sum(predvalid_svm != validation_set$activity) / length(validation_set$activity)
print(errvalid_svm)

errvalid_tree <- sum(predvalid_tree != validation_set$activity) / length(validation_set$activity)
print(errvalid_tree)
```

We obtain 17% error using random forest, 25% using svm and 21% using trees. Given that a random forest training is natively executed using boostrap technique, it is reasonable to obtain a lower error and does not seem that the model is overfitting the data, returning a moderate error but still allowing a decent bias.

Larger errors using svm and tree are probably given by the nature of the reduced dataset, so in order to obtain values that are comparable to a random forest using bootstrap, we enlarge the training set using a greater number of subjects (in this case we have a training set made of 5867 observations of 562 variables) and we check the predictors again.

```{r}
mod_ltree <- tree(activity ~ ., data=ltraining_set)
print(mod_ltree)

mod_lsvm <- svm(activity ~ ., data=ltraining_set)
print(mod_lsvm)
```

Printing the tree now shows how the first split are done using a mixture of frequency, time and angle variables: this supports the idea that all variables contribute to the decision, no matter their specific domain. Now check predictions of the new models.

```{r}
predvalid_ltree <- predict(mod_ltree, validation_set, type="class")
errvalid_ltree <- sum(predvalid_ltree != validation_set$activity) / length(validation_set$activity)
print(errvalid_ltree)

predvalid_lsvm <- predict(mod_lsvm, validation_set)
errvalid_lsvm <- sum(predvalid_lsvm != validation_set$activity) / length(validation_set$activity)
print(errvalid_lsvm)
```

Using tree and svm on larger dataset significantly reduces the error, svm in particular benefits of roughly 10% reduction. Now it's time to validate data on our test set.

```{r}
pred_randomforest <- predict(mod_randomforest, test_set)
pred_svm <- predict(mod_lsvm, test_set)
pred_tree <- predict(mod_ltree, test_set, type="class")

err_randomforest <- sum(pred_randomforest != test_set$activity) / length(test_set$activity)
print(err_randomforest)

err_svm <- sum(pred_svm != test_set$activity) / length(test_set$activity)
print(err_svm)

err_tree <- sum(pred_tree != test_set$activity) / length(test_set$activity)
print(err_tree)
```

Validating results on test set show that random forest (using bootstrap) and svm (using a larger data set) produce comparable results, with error < 10%, while the simple tree in this case is slightly worse.

The intersting part of using a tree is that it can be easily examined performing a k-fold cross validation on the tree [fig. 1b] to see how it can be optimized. 

```{r}
cross_validation_tree <- cv.tree(mod_ltree, FUN=prune.tree, method="misclass")
plot(cross_validation_tree)
mod_prunetree <- prune.tree(mod_ltree,best=6)
```

We see a significant reduction of misclassifications for a depth larger than 6, this can help creating a simplified version of the tree in order to achieve comparable error with less variables. We can then validate our pruned tree against the test set.

```{r}
pred_prunetree <- predict(mod_prunetree, test_set, type="class")
err_prunetree <- sum(pred_prunetree != test_set$activity) / length(test_set$activity)
print(err_prunetree)
```

We obtain a slightly higher ~ 1%, but the reduction of the number of variables is much greater, allowing to select the significant variables for a correct classifcation [fig. 1c].

Image
--------------------------------------------------------

```{r fig.width=8, fig.height=4}
pdf(file="a2_figure.pdf",height=4,width=8)
par(mfrow=c(1,3))

# fig 1a
plot_column <- 12
plot(training_set[,plot_column],pch=20,col=as.numeric(training_set$activity),ylab="Acceleration Z axis",xlab="observation",main="(1a)")
legend(0,0.2,title="Activity",legend=unique(training_set$activity),col=unique(training_set$activity),pch=20)

# fig 1c
plot(cross_validation_tree, main="(1b)")

# fig 1c
plot(mod_prunetree, type="uniform")
text(mod_prunetree, cex=0.8)
mtext("(1c)",line=1)

dev.off()
```

Figure 1a (left panel). shows coloured patterns for each activity, the acceleration on Z axis is taking as a sample, but patterns are recurring across most of the variables in the dataset, suggesting they all contribute to the statistical models. 
Figure 1b (central panel). shows the number of misclassifications for a prediction tree trained on a large dataset, suggesting that it is reasonable to prune it at depth 6. 
Figure 1c (right panel). shows the simplified structure of the pruned tree with the relevant variables used for the classification (we need to use variable names here since it is structure to the tree). 

Conclusions
--------------------------------------------------------

The exploratory analysis revealed that a high number of variables present in these observations define values in different domains, being time, freqency and angles. Further analysis reveals a clear clustering of activities around specific values of acceleration across all 3 axes [fig. 1a]

Prediction defined as outcomes for activities with all the variables as covariates and using random forest based on bootstrap techniques to define the data set confirms to be comparable to ordinary tree and svm models trained on a larger population. 

Exploring the tree models reveals that it's possible to subset the number of variables used for modeling, significantly reducing the complexity of the model.

Training the random forest on the large dataset would increase the computing time of a large scale, and would probably provide an overfitted model. Potential problems of this analysis are given by the size of the dataset and further analysis should be carried on in case we need to build models related to more specific activities (such as the CPR mentioned in the introduction of this paper)

References
--------------------------------------------------------
1. data collection description, page accessed on march 8th http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 
2. data analysis assignment n.2, page accessed throughout the days of the assignement until march 11th https://class.coursera.org/dataanalysis-001/human_grading/index
3. Activity Recognition using Cell Phone Accelerometers, Jennifer R. Kwapisz, Gary M. Weiss, Samuel A. Moore, Department of Computer and Information Science http://www.cis.fordham.edu/wisdm/public_files/sensorKDD-2010.pdf
4. about accelerometers, gyroscopes, and relevant elements in the data set, https://class.coursera.org/dataanalysis-001/forum/thread?thread_id=2771
5. Jerk in physics, page accessed on 8th march, http://en.wikipedia.org/wiki/Jerk_(physics)
6. Elements of statistical learning http://www-stat.stanford.edu/~tibs/ElemStatLearn/
7. Lifesaver, adoption of gesture prediction on tablets, https://life-saver.org.uk/